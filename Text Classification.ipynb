{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path=\"C:\\\\Users\\\\Anil\\\\Downloads\\\\20_newsgroups-20190710T162656Z-001\\\\20_newsgroups\"\n",
    "#all the folders in directory\n",
    "folder=os.listdir(path)\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]#files in folders\n",
    "y=[]#folders\n",
    "for fname in folder:\n",
    "    f_path=path+\"\\\\\"+fname\n",
    "    files=os.listdir(f_path)#files in current folder\n",
    "    for cur_file in files:\n",
    "        x.append(cur_file)\n",
    "        y.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops=set(stopwords.words('english'))\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def removepunc(word):\n",
    "    for p in punctuation:\n",
    "        word.replace(p,'')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buld vocabulary\n",
    "vocabulary={}\n",
    "for i in range(len(x_train)):\n",
    "    cur_path=path+\"\\\\\"+y_train[i]+\"\\\\\"+x_train[i]\n",
    "    fileopen=open(cur_path,'r',errors='ignore')#open file\n",
    "    record=fileopen.read()\n",
    "    words=record.split()\n",
    "    for cur_word in words:\n",
    "        cur_word=removepunc(cur_word)\n",
    "        if(len(cur_word)>2):\n",
    "            if(cur_word.lower() in stops):\n",
    "                continue\n",
    "            else:\n",
    "                if(cur_word.lower() in vocabulary):\n",
    "                    vocabulary[cur_word.lower()]+=1\n",
    "                else:\n",
    "                    vocabulary[cur_word.lower()]=1\n",
    "    fileopen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355496"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding frequencies\n",
    "freq=sorted(vocabulary.values())\n",
    "Y=set(freq)\n",
    "Y=list(Y)\n",
    "wordcount=[]\n",
    "for i in Y:\n",
    "    wordcount.append(sum(value==i for value in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select top 3000 features\n",
    "selected_feature=[]\n",
    "import operator\n",
    "sorted_vocab = sorted(vocabulary.items(), key=operator.itemgetter(1)) #sorting the vocabulary wrt the frequency\n",
    "vocab_len=len(sorted_vocab)\n",
    "for i in range(vocab_len-1,vocab_len-3000-1,-1):\n",
    "    selected_feature.append(sorted_vocab[i][0])\n",
    "len(selected_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the given data as required\n",
    "data=np.ndarray(shape=(len(x_train),len(selected_feature)))\n",
    "for i in range(len(x_train)):\n",
    "    count=np.zeros(len(selected_feature))\n",
    "    cur_path=path+\"\\\\\"+y_train[i]+\"\\\\\"+x_train[i]\n",
    "    fileopen=open(cur_path,'r',errors='ignore')\n",
    "    record=fileopen.read()\n",
    "    words=record.split()\n",
    "    for cur_word in words:\n",
    "        cur_word=removepunc(cur_word)\n",
    "        col=0\n",
    "        for j in range(len(selected_feature)):\n",
    "            if(cur_word.lower()==selected_feature[j]):\n",
    "                count[j]+=1\n",
    "                col=j\n",
    "                break\n",
    "        \n",
    "        data[i][col]=count[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(data)\n",
    "df.columns=selected_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from:</th>\n",
       "      <th>subject:</th>\n",
       "      <th>date:</th>\n",
       "      <th>newsgroups:</th>\n",
       "      <th>message-id:</th>\n",
       "      <th>lines:</th>\n",
       "      <th>path:</th>\n",
       "      <th>apr</th>\n",
       "      <th>organization:</th>\n",
       "      <th>gmt</th>\n",
       "      <th>...</th>\n",
       "      <th>learning</th>\n",
       "      <th>was.</th>\n",
       "      <th>accounts</th>\n",
       "      <th>wood</th>\n",
       "      <th>officer</th>\n",
       "      <th>artificial</th>\n",
       "      <th>(of</th>\n",
       "      <th>cities</th>\n",
       "      <th>automatically</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   from:  subject:  date:  newsgroups:  message-id:  lines:  path:  apr  \\\n",
       "0    1.0       1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "1    1.0       1.0    1.0          1.0          1.0     1.0    1.0  0.0   \n",
       "2    1.0       1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "3    1.0       1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "4    1.0       1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "\n",
       "   organization:  gmt          ...            learning  was.  accounts  wood  \\\n",
       "0            1.0  1.0          ...                 0.0   0.0       0.0   0.0   \n",
       "1            1.0  1.0          ...                 0.0   0.0       0.0   0.0   \n",
       "2            1.0  1.0          ...                 0.0   0.0       0.0   0.0   \n",
       "3            1.0  1.0          ...                 0.0   0.0       0.0   0.0   \n",
       "4            1.0  1.0          ...                 0.0   0.0       0.0   0.0   \n",
       "\n",
       "   officer  artificial  (of  cities  automatically                      y  \n",
       "0      0.0         0.0  0.0     0.0            0.0              sci.space  \n",
       "1      0.0         0.0  0.0     0.0            0.0  talk.politics.mideast  \n",
       "2      0.0         0.0  0.0     0.0            0.0     rec.sport.baseball  \n",
       "3      0.0         0.0  0.0     0.0            0.0        sci.electronics  \n",
       "4      0.0         0.0  0.0     0.0            0.0           misc.forsale  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"]=y_train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from:</th>\n",
       "      <th>subject:</th>\n",
       "      <th>date:</th>\n",
       "      <th>newsgroups:</th>\n",
       "      <th>message-id:</th>\n",
       "      <th>lines:</th>\n",
       "      <th>path:</th>\n",
       "      <th>apr</th>\n",
       "      <th>organization:</th>\n",
       "      <th>gmt</th>\n",
       "      <th>...</th>\n",
       "      <th>learning</th>\n",
       "      <th>was.</th>\n",
       "      <th>accounts</th>\n",
       "      <th>wood</th>\n",
       "      <th>officer</th>\n",
       "      <th>artificial</th>\n",
       "      <th>(of</th>\n",
       "      <th>cities</th>\n",
       "      <th>automatically</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   from:  subject:  date:  newsgroups:  message-id:  lines:  path:  apr  \\\n",
       "0    1.0       1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "1    1.0       1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "2    1.0       1.0    1.0          1.0          1.0     1.0    1.0  2.0   \n",
       "3    1.0       1.0    1.0          1.0          1.0     1.0    1.0  0.0   \n",
       "4    1.0       1.0    1.0          1.0          1.0     1.0    1.0  2.0   \n",
       "\n",
       "   organization:  gmt           ...            learning  was.  accounts  wood  \\\n",
       "0            1.0  1.0           ...                 0.0   0.0       0.0   0.0   \n",
       "1            1.0  1.0           ...                 0.0   0.0       0.0   0.0   \n",
       "2            1.0  2.0           ...                 0.0   0.0       0.0   0.0   \n",
       "3            0.0  0.0           ...                 0.0   0.0       0.0   0.0   \n",
       "4            0.0  0.0           ...                 0.0   0.0       0.0   0.0   \n",
       "\n",
       "   officer  artificial  (of  cities  automatically                       y  \n",
       "0      0.0         0.0  0.0     0.0            0.0  soc.religion.christian  \n",
       "1      0.0         0.0  0.0     0.0            0.0                 sci.med  \n",
       "2      0.0         0.0  0.0     0.0            0.0      talk.politics.guns  \n",
       "3      0.0         0.0  0.0     0.0            0.0   talk.politics.mideast  \n",
       "4      0.0         0.0  0.0     0.0            0.0         sci.electronics  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert testing data to required format\n",
    "data=np.ndarray(shape=(len(x_test),len(selected_feature)))\n",
    "for i in range(len(x_test)):\n",
    "    count=np.zeros(len(selected_feature))\n",
    "    cur_path=path+\"\\\\\"+y_test[i]+\"\\\\\"+x_test[i]\n",
    "    fileopen=open(cur_path,'r',errors='ignore')\n",
    "    record=fileopen.read()\n",
    "    words=record.split()\n",
    "    for cur_word in words:\n",
    "        cur_word=removepunc(cur_word)\n",
    "        col=0\n",
    "        for j in range(len(selected_feature)):\n",
    "            if(cur_word.lower()==selected_feature[j]):\n",
    "                count[j]+=1\n",
    "                col=j\n",
    "                break\n",
    "        \n",
    "        data[i][col]=count[col]\n",
    "        \n",
    "df_test=pd.DataFrame(data)\n",
    "df_test.columns=selected_feature\n",
    "df_test[\"y\"]=y_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train,y_train):\n",
    "    result={}\n",
    "    result[\"total_data\"]=len(y_train)\n",
    "    classes=set(y_train)\n",
    "    for cur_class in classes:\n",
    "        x_train_rows=x_train[(y_train==cur_class)]\n",
    "        y_train_rows=y_train[(y_train==cur_class)]\n",
    "        result[cur_class]={}\n",
    "        result[cur_class][\"total_count\"]=len(y_train_rows)\n",
    "        num_features=x_train.shape[1]\n",
    "        for i in range (1,num_features+1):\n",
    "            result[cur_class][i]=x_train_rows[:,i-1].sum()\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x,cur_class,result):\n",
    "    output=np.log(result[cur_class][\"total_count\"])-np.log(result[\"total_data\"])\n",
    "    num_features=len(result[cur_class].keys())-1\n",
    "    for i in range(1,num_features+1):\n",
    "        if(x[i-1]==0):\n",
    "            continue;\n",
    "        count_curclass_xi=result[cur_class][i]+1\n",
    "        total_count=result[cur_class][\"total_count\"]+len(result[cur_class])\n",
    "        cur_prob=np.log(count_curclass_xi)-np.log(total_count)\n",
    "        output=output+cur_prob\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictsinglepoint(x,result):\n",
    "    classes=result.keys()\n",
    "    best_p=-1000\n",
    "    best_class=-1;\n",
    "    for cur_class in classes:\n",
    "        if(cur_class==\"total_data\"):\n",
    "            continue;\n",
    "        val=probability(x,cur_class,result)\n",
    "        if(val>best_p):\n",
    "            best_p=val\n",
    "            best_class=cur_class\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,result):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predictsinglepoint(x,result))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features=k[:,:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=fit(x_train_features,np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_features=j[:,:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=predict(x_test_features,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                      -1       0.00      0.00      0.00         0\n",
      "             alt.atheism       0.74      0.76      0.75       233\n",
      "           comp.graphics       0.78      0.63      0.70       253\n",
      " comp.os.ms-windows.misc       0.98      0.53      0.69       249\n",
      "comp.sys.ibm.pc.hardware       0.82      0.70      0.76       240\n",
      "   comp.sys.mac.hardware       0.98      0.53      0.69       236\n",
      "          comp.windows.x       0.77      0.83      0.80       246\n",
      "            misc.forsale       0.94      0.40      0.57       252\n",
      "               rec.autos       0.94      0.47      0.62       267\n",
      "         rec.motorcycles       1.00      0.39      0.56       255\n",
      "      rec.sport.baseball       0.99      0.64      0.78       251\n",
      "        rec.sport.hockey       0.98      0.86      0.92       239\n",
      "               sci.crypt       0.37      0.91      0.53       229\n",
      "         sci.electronics       0.99      0.26      0.41       285\n",
      "                 sci.med       0.94      0.61      0.74       231\n",
      "               sci.space       0.91      0.61      0.73       247\n",
      "  soc.religion.christian       0.96      0.96      0.96       245\n",
      "      talk.politics.guns       0.83      0.46      0.59       250\n",
      "   talk.politics.mideast       0.57      0.89      0.69       297\n",
      "      talk.politics.misc       0.19      0.80      0.31       254\n",
      "      talk.religion.misc       0.69      0.38      0.49       243\n",
      "\n",
      "               micro avg       0.63      0.63      0.63      5002\n",
      "               macro avg       0.78      0.60      0.63      5002\n",
      "            weighted avg       0.82      0.63      0.66      5002\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  8 178   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0\n",
      "    7  13  25]\n",
      " [  6   0 160   1   0   0   7   0   0   0   0   0  41   0   0   3   0   0\n",
      "    8  25   2]\n",
      " [  3   0  12 131   2   0  33   0   0   0   0   0  30   0   0   2   1   2\n",
      "    2  31   0]\n",
      " [  2   0   3   0 169   1   4   2   0   0   0   1  38   1   0   0   0   0\n",
      "    3  16   0]\n",
      " [  2   0   1   1  13 126   5   1   0   0   0   0  38   0   2   0   0   2\n",
      "    7  38   0]\n",
      " [  4   0   1   0   1   0 205   0   0   0   0   0  17   0   1   0   0   0\n",
      "    1  16   0]\n",
      " [  0   0   8   0  17   1   6 102   5   0   1   0  45   0   2   3   0   0\n",
      "   14  47   1]\n",
      " [  1   1   0   0   0   0   0   3 125   0   0   0  10   0   1   1   0   2\n",
      "   24  99   0]\n",
      " [  0   2   1   0   1   0   0   0   1  99   0   0  12   0   0   0   0   4\n",
      "   26 108   1]\n",
      " [  1   2   1   0   0   0   1   0   0   0 161   3   2   0   0   0   0   2\n",
      "   19  59   0]\n",
      " [  2   0   0   0   0   0   1   0   0   0   0 206   1   0   0   1   0   0\n",
      "    3  25   0]\n",
      " [  4   1   0   0   0   0   1   0   0   0   0   0 209   0   0   0   0   0\n",
      "    1  13   0]\n",
      " [  1   1  12   0   4   0   1   0   2   0   0   0  95  74   2   5   0   4\n",
      "   11  72   1]\n",
      " [  7   2   4   0   0   0   1   0   0   0   0   0   7   0 140   0   1   0\n",
      "   12  55   2]\n",
      " [  9   1   1   0   0   0   0   0   0   0   0   0   5   0   1 150   0   0\n",
      "   13  66   1]\n",
      " [  9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 235   0\n",
      "    1   0   0]\n",
      " [ 12   0   0   0   0   0   0   0   0   0   0   0   7   0   0   0   0 114\n",
      "    9 106   2]\n",
      " [ 21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  264  12   0]\n",
      " [ 13   1   1   0   0   0   0   0   0   0   0   0   2   0   0   0   0   4\n",
      "   24 202   7]\n",
      " [  7  50   1   0   0   0   0   0   0   0   0   0   2   0   0   0   8   4\n",
      "   14  65  92]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anil\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_features,np.array(y_train))\n",
    "y_pred2=clf.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.70      0.78      0.74       233\n",
      "           comp.graphics       0.78      0.74      0.76       253\n",
      " comp.os.ms-windows.misc       0.87      0.80      0.83       249\n",
      "comp.sys.ibm.pc.hardware       0.84      0.88      0.86       240\n",
      "   comp.sys.mac.hardware       0.84      0.90      0.87       236\n",
      "          comp.windows.x       0.88      0.84      0.86       246\n",
      "            misc.forsale       0.69      0.91      0.79       252\n",
      "               rec.autos       0.82      0.90      0.86       267\n",
      "         rec.motorcycles       0.85      0.96      0.90       255\n",
      "      rec.sport.baseball       0.97      0.96      0.96       251\n",
      "        rec.sport.hockey       0.99      0.96      0.97       239\n",
      "               sci.crypt       0.96      0.87      0.92       229\n",
      "         sci.electronics       0.81      0.88      0.84       285\n",
      "                 sci.med       0.93      0.86      0.89       231\n",
      "               sci.space       0.95      0.85      0.90       247\n",
      "  soc.religion.christian       0.96      0.97      0.97       245\n",
      "      talk.politics.guns       0.74      0.89      0.81       250\n",
      "   talk.politics.mideast       0.93      0.77      0.84       297\n",
      "      talk.politics.misc       0.69      0.56      0.62       254\n",
      "      talk.religion.misc       0.60      0.49      0.54       243\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      5002\n",
      "               macro avg       0.84      0.84      0.84      5002\n",
      "            weighted avg       0.84      0.84      0.84      5002\n",
      "\n",
      "[[182   1   0   0   0   0   2   0   8   0   0   0   0   0   0   1   1   1\n",
      "    5  32]\n",
      " [  2 187  15  11   8   5   8   4   1   1   0   0   7   3   0   0   0   0\n",
      "    0   1]\n",
      " [  0  10 198  10   2  11   8   1   0   0   0   1   5   0   3   0   0   0\n",
      "    0   0]\n",
      " [  0   3   2 210   8   0  12   1   1   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   9 213   1   6   1   0   0   0   0   5   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  13   5   2   3 206   3   1   4   1   0   0   6   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   4   1   1 230   6   1   0   0   2   5   0   1   0   0   0\n",
      "    1   0]\n",
      " [  0   1   0   0   1   1   9 239   6   0   0   0   5   1   0   0   4   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   1   3   2 246   0   0   0   1   0   0   0   0   0\n",
      "    1   0]\n",
      " [  1   1   0   0   0   0   7   1   0 240   0   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   4   1   1   3 229   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   5   1   1   4   1   3   1   1   0   0 200   4   1   0   0   2   0\n",
      "    3   2]\n",
      " [  0   5   2   3   7   3   8   5   0   0   0   0 250   0   0   0   1   0\n",
      "    0   1]\n",
      " [  3   5   0   1   2   3   5   4   3   0   1   0   3 199   2   0   0   0\n",
      "    0   0]\n",
      " [  1   5   1   0   2   0   4   8   2   0   1   0   3   1 209   0   4   0\n",
      "    3   3]\n",
      " [  1   1   1   0   0   0   0   0   0   0   0   0   0   2   0 238   1   1\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   3   3   3   0   0   3   2   0   0   0 222   1\n",
      "    7   5]\n",
      " [ 10   0   2   0   2   1   9   3   9   0   0   1   4   3   1   1   2 228\n",
      "   14   7]\n",
      " [  4   2   0   0   0   0   3   7   4   2   0   1   2   3   0   0  44  12\n",
      "  142  28]\n",
      " [ 55   0   0   0   0   0   4   3   1   0   0   0   5   1   1   8  17   1\n",
      "   29 118]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
