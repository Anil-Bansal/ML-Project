{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path=\"C:\\\\Users\\\\Anil\\\\Downloads\\\\20_newsgroups-20190710T162656Z-001\\\\20_newsgroups\"\n",
    "#all the folders in directory\n",
    "folder=os.listdir(path)\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]#files in folders\n",
    "y=[]#folders\n",
    "for fname in folder:\n",
    "    f_path=path+\"\\\\\"+fname\n",
    "    files=os.listdir(f_path)#files in current folder\n",
    "    for cur_file in files:\n",
    "        x.append(cur_file)\n",
    "        y.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops=set(stopwords.words('english'))\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def removepunc(word):\n",
    "    for p in punctuation:\n",
    "        word.replace(p,'')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buld vocabulary\n",
    "vocabulary={}\n",
    "for i in range(len(x_train)):\n",
    "    cur_path=path+\"\\\\\"+y_train[i]+\"\\\\\"+x_train[i]\n",
    "    fileopen=open(cur_path,'r',errors='ignore')#open file\n",
    "    record=fileopen.read()\n",
    "    words=record.split()\n",
    "    for cur_word in words:\n",
    "        cur_word=removepunc(cur_word)\n",
    "        if(len(cur_word)>2):\n",
    "            if(cur_word.lower() in stops):\n",
    "                continue\n",
    "            else:\n",
    "                if(cur_word.lower() in vocabulary):\n",
    "                    vocabulary[cur_word.lower()]+=1\n",
    "                else:\n",
    "                    vocabulary[cur_word.lower()]=1\n",
    "    fileopen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369590"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding frequencies\n",
    "#freq=sorted(vocabulary.values())\n",
    "#Y=set(freq)\n",
    "#Y=list(Y)\n",
    "#wordcount=[]\n",
    "#for i in Y:\n",
    "#    wordcount.append(sum(value==i for value in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select top 3000 features\n",
    "selected_feature=[]\n",
    "import operator\n",
    "sorted_vocab = sorted(vocabulary.items(), key=operator.itemgetter(1)) #sorting the vocabulary wrt the frequency\n",
    "vocab_len=len(sorted_vocab)\n",
    "for i in range(vocab_len-1,vocab_len-3000-1,-1):\n",
    "    selected_feature.append(sorted_vocab[i][0])\n",
    "len(selected_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the given data as required\n",
    "data=np.ndarray(shape=(len(x_train),len(selected_feature)))\n",
    "for i in range(len(x_train)):\n",
    "    count=np.zeros(len(selected_feature))\n",
    "    cur_path=path+\"\\\\\"+y_train[i]+\"\\\\\"+x_train[i]\n",
    "    fileopen=open(cur_path,'r',errors='ignore')\n",
    "    record=fileopen.read()\n",
    "    words=record.split()\n",
    "    for cur_word in words:\n",
    "        cur_word=removepunc(cur_word)\n",
    "        col=0\n",
    "        for j in range(len(selected_feature)):\n",
    "            if(cur_word.lower()==selected_feature[j]):\n",
    "                count[j]+=1\n",
    "                col=j\n",
    "                break\n",
    "        \n",
    "        data[i][col]=count[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(data)\n",
    "df.columns=selected_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from:</th>\n",
       "      <th>subject:</th>\n",
       "      <th>date:</th>\n",
       "      <th>newsgroups:</th>\n",
       "      <th>lines:</th>\n",
       "      <th>message-id:</th>\n",
       "      <th>path:</th>\n",
       "      <th>apr</th>\n",
       "      <th>organization:</th>\n",
       "      <th>gmt</th>\n",
       "      <th>...</th>\n",
       "      <th>phil</th>\n",
       "      <th>think,</th>\n",
       "      <th>christ.</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>myself.</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>commit</th>\n",
       "      <th>forms</th>\n",
       "      <th>animals</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   from:  subject:  date:  newsgroups:  lines:  message-id:  path:  apr  \\\n",
       "0    1.0       1.0    1.0          1.0     1.0          1.0    1.0  1.0   \n",
       "1    1.0       1.0    1.0          1.0     1.0          1.0    1.0  1.0   \n",
       "2    1.0       1.0    1.0          1.0     1.0          1.0    1.0  1.0   \n",
       "3    1.0       1.0    1.0          1.0     1.0          1.0    1.0  1.0   \n",
       "4    1.0       1.0    1.0          1.0     1.0          1.0    1.0  1.0   \n",
       "\n",
       "   organization:  gmt         ...          phil  think,  christ.  intelligent  \\\n",
       "0            1.0  1.0         ...           0.0     0.0      0.0          0.0   \n",
       "1            1.0  1.0         ...           0.0     0.0      0.0          0.0   \n",
       "2            1.0  0.0         ...           0.0     0.0      0.0          0.0   \n",
       "3            1.0  1.0         ...           0.0     0.0      0.0          0.0   \n",
       "4            1.0  1.0         ...           0.0     0.0      0.0          0.0   \n",
       "\n",
       "   myself.  reasoning  commit  forms  animals                   y  \n",
       "0      0.0        0.0     0.0    0.0      0.0     rec.motorcycles  \n",
       "1      0.0        0.0     0.0    0.0      0.0       comp.graphics  \n",
       "2      0.0        0.0     0.0    0.0      0.0           rec.autos  \n",
       "3      0.0        0.0     0.0    0.0      0.0        misc.forsale  \n",
       "4      0.0        0.0     0.0    0.0      0.0  rec.sport.baseball  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"]=y_train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from:</th>\n",
       "      <th>subject:</th>\n",
       "      <th>date:</th>\n",
       "      <th>newsgroups:</th>\n",
       "      <th>lines:</th>\n",
       "      <th>message-id:</th>\n",
       "      <th>path:</th>\n",
       "      <th>apr</th>\n",
       "      <th>organization:</th>\n",
       "      <th>gmt</th>\n",
       "      <th>...</th>\n",
       "      <th>phil</th>\n",
       "      <th>think,</th>\n",
       "      <th>christ.</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>myself.</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>commit</th>\n",
       "      <th>forms</th>\n",
       "      <th>animals</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   from:  subject:  date:  newsgroups:  lines:  message-id:  path:  apr  \\\n",
       "0    1.0       1.0    1.0          1.0     1.0          1.0    1.0  1.0   \n",
       "1    1.0       1.0    1.0          1.0     1.0          1.0    1.0  1.0   \n",
       "2    1.0       1.0    1.0          1.0     1.0          1.0    1.0  2.0   \n",
       "3    1.0       1.0    1.0          1.0     1.0          1.0    1.0  0.0   \n",
       "4    1.0       1.0    1.0          1.0     1.0          1.0    1.0  2.0   \n",
       "\n",
       "   organization:  gmt           ...            phil  think,  christ.  \\\n",
       "0            1.0  1.0           ...             0.0     0.0      0.0   \n",
       "1            1.0  1.0           ...             0.0     0.0      0.0   \n",
       "2            1.0  2.0           ...             0.0     0.0      0.0   \n",
       "3            0.0  0.0           ...             0.0     0.0      0.0   \n",
       "4            0.0  0.0           ...             0.0     0.0      0.0   \n",
       "\n",
       "   intelligent  myself.  reasoning  commit  forms  animals  \\\n",
       "0          0.0      0.0        0.0     0.0    0.0      0.0   \n",
       "1          0.0      0.0        0.0     0.0    0.0      0.0   \n",
       "2          0.0      0.0        0.0     0.0    0.0      0.0   \n",
       "3          0.0      0.0        0.0     0.0    0.0      0.0   \n",
       "4          0.0      0.0        0.0     0.0    0.0      0.0   \n",
       "\n",
       "                        y  \n",
       "0  soc.religion.christian  \n",
       "1                 sci.med  \n",
       "2      talk.politics.guns  \n",
       "3   talk.politics.mideast  \n",
       "4         sci.electronics  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert testing data to required format\n",
    "data=np.ndarray(shape=(len(x_test),len(selected_feature)))\n",
    "for i in range(len(x_test)):\n",
    "    count=np.zeros(len(selected_feature))\n",
    "    cur_path=path+\"\\\\\"+y_test[i]+\"\\\\\"+x_test[i]\n",
    "    fileopen=open(cur_path,'r',errors='ignore')\n",
    "    record=fileopen.read()\n",
    "    words=record.split()\n",
    "    for cur_word in words:\n",
    "        cur_word=removepunc(cur_word)\n",
    "        col=0\n",
    "        for j in range(len(selected_feature)):\n",
    "            if(cur_word.lower()==selected_feature[j]):\n",
    "                count[j]+=1\n",
    "                col=j\n",
    "                break\n",
    "        \n",
    "        data[i][col]=count[col]\n",
    "        \n",
    "df_test=pd.DataFrame(data)\n",
    "df_test.columns=selected_feature\n",
    "df_test[\"y\"]=y_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train,y_train):\n",
    "    result={}\n",
    "    result[\"total_data\"]=len(y_train)\n",
    "    classes=set(y_train)\n",
    "    for cur_class in classes:\n",
    "        x_train_rows=x_train[(y_train==cur_class)]\n",
    "        y_train_rows=y_train[(y_train==cur_class)]\n",
    "        result[cur_class]={}\n",
    "        result[cur_class][\"total_count\"]=len(y_train_rows)\n",
    "        result[cur_class][\"total_words\"]=x_train_rows.sum()\n",
    "        num_features=x_train.shape[1]\n",
    "        for i in range (1,num_features+1):\n",
    "                result[cur_class][i]=x_train_rows[:,i-1].sum()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x,cur_class,result):\n",
    "    output=np.log(result[cur_class][\"total_count\"])-np.log(result[\"total_data\"])\n",
    "    num_features=len(result[cur_class].keys())-1\n",
    "    for i in range(1,len(x)+1):\n",
    "        if(x[i-1]==0):\n",
    "            continue\n",
    "        count_curclass_xi=result[cur_class][i]+1\n",
    "        total_count=result[cur_class][\"total_words\"]+num_features\n",
    "        cur_prob=np.log(count_curclass_xi)-np.log(total_count)\n",
    "        output=output+cur_prob\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictsinglepoint(x,result):\n",
    "    classes=result.keys()\n",
    "    best_p=-1000\n",
    "    best_class=-1;\n",
    "    for cur_class in classes:\n",
    "        if(cur_class==\"total_data\"):\n",
    "            continue;\n",
    "        val=probability(x,cur_class,result)\n",
    "        if(val>best_p):\n",
    "            best_p=val\n",
    "            best_class=cur_class\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,result):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predictsinglepoint(x,result))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features=k[:,:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=fit(x_train_features,np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_features=j[:,:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=predict(x_test_features,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                      -1       0.00      0.00      0.00         0\n",
      "             alt.atheism       0.75      0.72      0.73       193\n",
      "           comp.graphics       0.88      0.67      0.76       201\n",
      " comp.os.ms-windows.misc       0.87      0.82      0.84       197\n",
      "comp.sys.ibm.pc.hardware       0.87      0.86      0.86       182\n",
      "   comp.sys.mac.hardware       0.81      0.90      0.85       193\n",
      "          comp.windows.x       0.94      0.86      0.90       205\n",
      "            misc.forsale       0.69      0.92      0.79       203\n",
      "               rec.autos       0.83      0.88      0.85       208\n",
      "         rec.motorcycles       0.84      0.95      0.89       204\n",
      "      rec.sport.baseball       0.97      0.91      0.94       199\n",
      "        rec.sport.hockey       1.00      0.91      0.95       202\n",
      "               sci.crypt       0.96      0.81      0.88       170\n",
      "         sci.electronics       0.78      0.90      0.84       233\n",
      "                 sci.med       0.94      0.80      0.86       187\n",
      "               sci.space       0.92      0.77      0.84       206\n",
      "  soc.religion.christian       0.99      0.78      0.88       193\n",
      "      talk.politics.guns       0.74      0.75      0.74       201\n",
      "   talk.politics.mideast       0.95      0.58      0.72       241\n",
      "      talk.politics.misc       0.74      0.41      0.53       193\n",
      "      talk.religion.misc       0.63      0.48      0.54       191\n",
      "\n",
      "               micro avg       0.78      0.78      0.78      4002\n",
      "               macro avg       0.81      0.75      0.77      4002\n",
      "            weighted avg       0.85      0.78      0.81      4002\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [ 19 139   0   0   0   1   0   2   0   7   0   0   0   1   0   0   0   2\n",
      "    0   2  20]\n",
      " [ 12   0 135  13   5   8   1  11   2   2   0   0   0   9   2   1   0   0\n",
      "    0   0   0]\n",
      " [  5   0   6 161   6   1   3   8   2   0   0   0   0   2   1   2   0   0\n",
      "    0   0   0]\n",
      " [  3   0   0   1 156   7   2   8   1   1   0   0   0   3   0   0   0   0\n",
      "    0   0   0]\n",
      " [  4   0   0   1   6 173   0   4   0   0   0   0   0   2   0   2   0   0\n",
      "    0   1   0]\n",
      " [  7   0   3   3   0   2 177   4   1   3   0   0   0   4   1   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   1   1   0 187   5   2   0   0   2   3   1   1   0   0\n",
      "    0   0   0]\n",
      " [  6   0   0   0   1   1   0   7 182   2   0   0   0   5   0   1   0   3\n",
      "    0   0   0]\n",
      " [  3   0   0   0   0   1   0   3   2 194   0   0   0   1   0   0   0   0\n",
      "    0   0   0]\n",
      " [  9   0   0   0   0   0   0   5   1   0 181   0   0   2   0   1   0   0\n",
      "    0   0   0]\n",
      " [  8   0   0   0   0   2   0   2   1   1   4 184   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [ 13   0   0   0   2   4   1   2   0   0   0   0 137   4   1   0   0   3\n",
      "    0   2   1]\n",
      " [  3   0   3   2   2   6   0   5   3   0   0   0   0 209   0   0   0   0\n",
      "    0   0   0]\n",
      " [ 13   1   4   1   1   2   1   2   2   2   0   0   0   4 150   2   0   0\n",
      "    0   0   2]\n",
      " [ 22   0   1   1   0   0   2   3   6   2   0   0   1   4   0 159   0   3\n",
      "    0   0   2]\n",
      " [ 39   0   0   1   0   0   1   0   0   0   0   0   0   0   1   0 151   0\n",
      "    0   0   0]\n",
      " [ 31   0   0   0   0   1   0   3   2   3   0   0   1   3   0   0   0 150\n",
      "    0   4   3]\n",
      " [ 51   5   0   2   0   3   1   8   3   6   0   0   1   6   2   1   0   2\n",
      "  140   6   4]\n",
      " [ 31   4   1   0   0   1   0   3   3   3   1   0   1   1   1   1   0  33\n",
      "    8  79  22]\n",
      " [ 28  37   0   0   0   0   0   4   2   2   0   0   0   4   0   1   1   8\n",
      "    0  13  91]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anil\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_features,np.array(y_train))\n",
    "y_pred2=clf.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.80      0.76       193\n",
      "           comp.graphics       0.83      0.74      0.78       201\n",
      " comp.os.ms-windows.misc       0.86      0.81      0.83       197\n",
      "comp.sys.ibm.pc.hardware       0.81      0.87      0.84       182\n",
      "   comp.sys.mac.hardware       0.83      0.90      0.87       193\n",
      "          comp.windows.x       0.90      0.88      0.89       205\n",
      "            misc.forsale       0.71      0.91      0.80       203\n",
      "               rec.autos       0.83      0.91      0.87       208\n",
      "         rec.motorcycles       0.88      0.97      0.92       204\n",
      "      rec.sport.baseball       0.97      0.95      0.96       199\n",
      "        rec.sport.hockey       0.99      0.96      0.98       202\n",
      "               sci.crypt       0.94      0.87      0.91       170\n",
      "         sci.electronics       0.79      0.86      0.82       233\n",
      "                 sci.med       0.95      0.87      0.91       187\n",
      "               sci.space       0.94      0.85      0.90       206\n",
      "  soc.religion.christian       0.96      0.96      0.96       193\n",
      "      talk.politics.guns       0.72      0.88      0.79       201\n",
      "   talk.politics.mideast       0.94      0.78      0.85       241\n",
      "      talk.politics.misc       0.70      0.52      0.60       193\n",
      "      talk.religion.misc       0.60      0.51      0.55       191\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      4002\n",
      "               macro avg       0.84      0.84      0.84      4002\n",
      "            weighted avg       0.84      0.84      0.84      4002\n",
      "\n",
      "[[154   0   0   0   0   0   1   0   5   0   0   0   0   0   0   0   3   1\n",
      "    4  25]\n",
      " [  2 149  12   7   8   2   7   2   1   0   0   0   8   2   1   0   0   0\n",
      "    0   0]\n",
      " [  0   9 160   7   1   6   6   1   0   0   0   1   4   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   2   1 158   7   1   9   1   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1  10 174   0   3   0   0   0   0   0   3   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   5   5   1   0 180   3   1   3   1   0   1   4   1   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   2   0   1 185   5   2   0   0   2   4   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   2   1   1   6 190   2   0   0   0   3   0   0   0   3   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   1   2   2 197   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   5   1   0 190   1   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   4   1   1   2 194   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1   1   4   1   2   0   0   0   0 148   4   1   0   0   2   0\n",
      "    3   2]\n",
      " [  0   4   2   3   7   3   5   6   0   0   0   0 201   0   0   0   1   0\n",
      "    0   1]\n",
      " [  2   3   1   1   2   2   2   2   2   0   0   0   5 162   2   0   0   0\n",
      "    0   1]\n",
      " [  0   5   1   0   1   0   3   5   1   0   0   0   3   1 176   0   5   0\n",
      "    2   3]\n",
      " [  1   0   1   0   0   1   0   0   0   0   0   0   0   1   0 186   1   1\n",
      "    1   0]\n",
      " [  0   0   0   0   1   0   3   3   3   0   0   2   2   0   0   0 176   1\n",
      "    6   4]\n",
      " [  8   0   2   0   2   1   7   3   5   0   0   1   4   2   1   1   1 188\n",
      "    9   6]\n",
      " [  4   0   0   1   0   0   4   3   2   3   0   2   1   1   1   0  37   9\n",
      "  101  24]\n",
      " [ 39   0   0   1   0   0   3   2   1   0   0   0   5   0   1   6  15   1\n",
      "   19  98]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
